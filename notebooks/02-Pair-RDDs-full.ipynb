{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your home directory clone the Spark in Action GitHub repository using the following command: \n",
    "   \n",
    "git clone https://github.com/spark-in-action/first-edition\n",
    "\n",
    "You might also want to have [Spark official documentation](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.SparkContext) open.\n",
    "\n",
    "First create a Spark context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(master='local[*]', appName=\"Spark course Pair RDDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `first-edition/ch04/ch04_data_transactions.txt` contains data about transactions your customers made. But before those transactions are fully processed, you can influence the final amounts and prices by changing the values in the file. Each line of the file contains these hash-delimited fields (delimited with \"#\"):\n",
    "* transaction date\n",
    "* transaction time\n",
    "* customer ID\n",
    "* product ID\n",
    "* quantity\n",
    "* product price   \n",
    "   \n",
    "Load the file into `transactions` RDD so that each element of the RDD is a list of strings (lines of the file split by the \"#\" sign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = sc.textFile(\"/home/spark/first-edition/ch04/ch04_data_transactions.txt\").map(lambda x: x.split(\"#\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not execute the following cell! \n",
    "\n",
    "Pyspark in Jupyter notebooks has trouble serializing classes declared inside the same notebook so if we want to use the below-defined class, we need to resort to a trick.\n",
    "\n",
    "Copy the `Transaction` class declaration into the file `/home/spark/first-edition/transaction.py` (using vi, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO NOT EXECUTE\n",
    "class Transaction:\n",
    "    def __init__(self, date, time, customer, product, quantity, price):\n",
    "        self.date = date\n",
    "        self.time = time\n",
    "        self.customer = customer\n",
    "        self.product = product\n",
    "        self.quantity = quantity\n",
    "        self.price = price\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"[%s, %s, %d, %d, %.3f, %.2f]\" % (self.date, self.time, self.customer, self.product, self.quantity, self.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute the following cell in order to add that file to this PySpark runtime instance and import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile('/home/spark/first-edition/transaction.py')\n",
    "from transaction import Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the declared class. Map each transaction from the `transactions` RDD into a `Transaction` object. Parse `customer` and `product` fields as `int`s and `quantity` and `price` as `float`s. \n",
    "\n",
    "Then create a `transByCust` Pair RDD whose keys are customer IDs and values are the original `Transaction` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transByCust = transactions.map(lambda tran: Transaction(tran[0], tran[1], int(tran[2]), int(tran[3]), float(tran[4]), float(tran[5]))).\\\n",
    "    map(lambda t: (t.customer, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first couple of elements of `transByCust` to see if everything went smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(51, [2015-03-30, 6:55 AM, 51, 68, 1.000, 9506.21]),\n",
       " (99, [2015-03-30, 7:39 PM, 99, 86, 5.000, 4107.59]),\n",
       " (79, [2015-03-30, 11:57 AM, 79, 58, 7.000, 2987.22]),\n",
       " (51, [2015-03-30, 12:46 AM, 51, 50, 6.000, 7501.89]),\n",
       " (86, [2015-03-30, 11:39 AM, 86, 24, 5.000, 8370.20]),\n",
       " (63, [2015-03-30, 10:35 AM, 63, 19, 5.000, 1023.57]),\n",
       " (23, [2015-03-30, 2:30 AM, 23, 77, 7.000, 5892.41]),\n",
       " (49, [2015-03-30, 7:41 PM, 49, 58, 4.000, 9298.18]),\n",
       " (97, [2015-03-30, 9:18 AM, 97, 86, 8.000, 9462.89]),\n",
       " (94, [2015-03-30, 10:06 PM, 94, 26, 4.000, 4199.15])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transByCust.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start analyzing the data.\n",
    "\n",
    "First, find out how many customers have made a purchase. (Hint: this is equal to the number of distinct keys.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transByCust.keys().distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which customer (ID) made the largest number of purchases? (Hints: Use Python's `sorted` method with the `key` option. Python `dict` can be converted into a list of tuples using `items()` method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k, v) for k, v in transByCust.countByKey().items()], key=lambda kc: kc[1])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which transactions did that customer make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2015-03-30, 6:18 AM, 53, 42, 5.000, 2197.85],\n",
       " [2015-03-30, 4:42 AM, 53, 44, 6.000, 9182.08],\n",
       " [2015-03-30, 2:51 AM, 53, 59, 5.000, 3154.43],\n",
       " [2015-03-30, 5:57 PM, 53, 31, 5.000, 6649.27],\n",
       " [2015-03-30, 6:11 AM, 53, 33, 10.000, 2353.72],\n",
       " [2015-03-30, 9:46 PM, 53, 93, 1.000, 2889.03],\n",
       " [2015-03-30, 4:15 PM, 53, 72, 7.000, 9157.55],\n",
       " [2015-03-30, 2:42 PM, 53, 94, 1.000, 921.65],\n",
       " [2015-03-30, 8:30 AM, 53, 38, 5.000, 4000.92],\n",
       " [2015-03-30, 6:06 AM, 53, 12, 6.000, 2174.02],\n",
       " [2015-03-30, 3:44 AM, 53, 47, 1.000, 7556.32],\n",
       " [2015-03-30, 10:25 AM, 53, 30, 2.000, 5107.00],\n",
       " [2015-03-30, 1:48 AM, 53, 58, 4.000, 718.93],\n",
       " [2015-03-30, 9:31 AM, 53, 18, 4.000, 8214.79],\n",
       " [2015-03-30, 9:04 AM, 53, 68, 4.000, 9246.59],\n",
       " [2015-03-30, 1:51 AM, 53, 40, 1.000, 4095.50],\n",
       " [2015-03-30, 1:53 PM, 53, 85, 9.000, 1630.24],\n",
       " [2015-03-30, 6:51 PM, 53, 100, 1.000, 1694.52],\n",
       " [2015-03-30, 7:39 PM, 53, 100, 8.000, 7885.35]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transByCust.lookup(53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower the price by 10% for each purchase of two or more products with ID 25. (Hint: Create a new RDD by executing `mapValues` on the first one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerPriceFor25(tran):\n",
    "    if tran.product == 25 and tran.quantity > 1:\n",
    "        tran.price *= 0.95\n",
    "    return tran\n",
    "\n",
    "transByCust2 = transByCust.mapValues(lowerPriceFor25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the matching transactions (in the old and the new RDD) and check if the change has been made. (Hint: Use `filter` on both RDDs and print out the results for visual inspection. Again, use `toInt` and `toDouble` as necessary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015-03-30, 6:26 PM, 17, 25, 6.000, 7193.11]\n",
      "[2015-03-30, 7:27 AM, 93, 25, 7.000, 2749.15]\n",
      "[2015-03-30, 1:07 AM, 68, 25, 9.000, 8391.61]\n",
      "[2015-03-30, 1:23 AM, 59, 25, 5.000, 5296.69]\n",
      "[2015-03-30, 9:45 AM, 42, 25, 10.000, 1363.97]\n",
      "[2015-03-30, 10:40 PM, 77, 25, 3.000, 3345.81]\n",
      "[2015-03-30, 12:53 PM, 22, 25, 9.000, 6996.42]\n",
      "[2015-03-30, 12:44 AM, 32, 25, 8.000, 8849.50]\n",
      "[2015-03-30, 5:30 PM, 75, 25, 10.000, 3557.01]\n",
      "TRANS NEW:\n",
      "[2015-03-30, 6:26 PM, 17, 25, 6.000, 6833.45]\n",
      "[2015-03-30, 7:27 AM, 93, 25, 7.000, 2611.69]\n",
      "[2015-03-30, 1:07 AM, 68, 25, 9.000, 7972.03]\n",
      "[2015-03-30, 1:23 AM, 59, 25, 5.000, 5031.86]\n",
      "[2015-03-30, 9:45 AM, 42, 25, 10.000, 1295.77]\n",
      "[2015-03-30, 10:40 PM, 77, 25, 3.000, 3178.52]\n",
      "[2015-03-30, 12:53 PM, 22, 25, 9.000, 6646.60]\n",
      "[2015-03-30, 12:44 AM, 32, 25, 8.000, 8407.02]\n",
      "[2015-03-30, 5:30 PM, 75, 25, 10.000, 3379.16]\n"
     ]
    }
   ],
   "source": [
    "for t in transByCust.filter(lambda tran: tran[1].product == 25 and tran[1].quantity > 1).map(lambda x: x[1]).collect():\n",
    "    print(t)\n",
    "print(\"TRANS NEW:\")\n",
    "for t in transByCust2.filter(lambda tran: tran[1].product == 25 and tran[1].quantity > 1).map(lambda x: x[1]).collect():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To all customers who bought five or more products with ID 81 in a single transaction give a complimentary item ID 70. Create a new transaction for this (using Pythons `copy.copy()` method) and use the original date and time, but set the price to zero. \n",
    "\n",
    "(Hint: use `flatMapValues`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compl70(tran):\n",
    "    import copy\n",
    "    if tran.product == 81 and tran.quantity >= 5:\n",
    "        newtran = copy.copy(tran)\n",
    "        newtran.price = 0.00\n",
    "        newtran.product = 70\n",
    "        newtran.quantity = 1\n",
    "        return [tran, newtran]\n",
    "    else:\n",
    "        return [tran]\n",
    "\n",
    "transByCust3 = transByCust2.flatMapValues(compl70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the changes have been made for the first customer that matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85, 77, 82, 47, 16, 10]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transByCust2.filter(lambda tran: tran[1].product == 81 and tran[1].quantity >= 5).map(lambda t: t[1].customer).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015-03-30, 10:49 AM, 77, 33, 8.000, 5440.16]\n",
      "[2015-03-30, 5:03 PM, 77, 18, 9.000, 5578.06]\n",
      "[2015-03-30, 11:08 PM, 77, 1, 3.000, 5188.87]\n",
      "[2015-03-30, 9:13 PM, 77, 29, 10.000, 7363.10]\n",
      "[2015-03-30, 4:00 PM, 77, 87, 8.000, 1343.98]\n",
      "[2015-03-30, 9:32 AM, 77, 4, 8.000, 3732.02]\n",
      "[2015-03-30, 9:34 PM, 77, 81, 5.000, 7798.28]\n",
      "[2015-03-30, 1:30 PM, 77, 49, 6.000, 102.77]\n",
      "[2015-03-30, 7:51 PM, 77, 58, 7.000, 7566.47]\n",
      "[2015-03-30, 10:40 PM, 77, 25, 3.000, 3178.52]\n",
      "[2015-03-30, 7:08 PM, 77, 61, 2.000, 4382.38]\n",
      "NEW\n",
      "[2015-03-30, 10:49 AM, 77, 33, 8.000, 5440.16]\n",
      "[2015-03-30, 5:03 PM, 77, 18, 9.000, 5578.06]\n",
      "[2015-03-30, 11:08 PM, 77, 1, 3.000, 5188.87]\n",
      "[2015-03-30, 9:13 PM, 77, 29, 10.000, 7363.10]\n",
      "[2015-03-30, 4:00 PM, 77, 87, 8.000, 1343.98]\n",
      "[2015-03-30, 9:32 AM, 77, 4, 8.000, 3732.02]\n",
      "[2015-03-30, 9:34 PM, 77, 81, 5.000, 7798.28]\n",
      "[2015-03-30, 9:34 PM, 77, 70, 1.000, 0.00]\n",
      "[2015-03-30, 1:30 PM, 77, 49, 6.000, 102.77]\n",
      "[2015-03-30, 7:51 PM, 77, 58, 7.000, 7566.47]\n",
      "[2015-03-30, 10:40 PM, 77, 25, 3.000, 3178.52]\n",
      "[2015-03-30, 7:08 PM, 77, 61, 2.000, 4382.38]\n"
     ]
    }
   ],
   "source": [
    "for t in transByCust2.filter(lambda t: t[1].customer == 77).map(lambda t: t[1]).collect():\n",
    "    print(t)\n",
    "print(\"NEW\")\n",
    "for t in transByCust3.filter(lambda t: t[1].customer == 77).map(lambda t: t[1]).collect():\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which customer has spent the most? (Hint: use `reduceByKey` to find the total amount, which is quantity times price, collect the results and then sort them using `sorted`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumAmountsByCust = transByCust2.mapValues(lambda t: t.quantity * t.price).reduceByKey(lambda v1, v2: v1 + v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 597122.3099999999)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sumAmountsByCust.collect(), key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining, sorting and grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you now need to create a report with product names and IDs and the total amounts sold. The product IDs and the amounts will come from the RDDs you created previously, but you still need product names.\n",
    "\n",
    "First, load the `/home/spark/first-edition/ch04/ch04_data_products.txt` file which contains: \n",
    "- product ID\n",
    "- product name\n",
    "- price\n",
    "- number of items \n",
    "\n",
    "for each product available in the storage, separated with hash signs (`#`). \n",
    "\n",
    "Create a Pair RDD whose keys are product IDs (as `int`s), and values are product names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = sc.textFile(\"/home/spark/first-edition/ch04/ch04_data_products.txt\").\\\n",
    "  map(lambda line: line.split(\"#\")).\\\n",
    "  map(lambda p: (int(p[0]), p[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this RDD and the RDD with transactions to obtain an RDD that contains tuples of product IDs, product names, and total amounts sold. (Hint: You first need to create adequate Pair RDDs so that they can be joined by product ID. Don't forget to sum up all the amounts for each product using `reduceByKey`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByProd = transByCust3.map(lambda tran: (tran[1].product, tran[1].quantity * tran[1].price)).\\\n",
    "    reduceByKey(lambda a1, a2: a1 + a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByProdNames = products.join(totalsByProd).map(lambda tbp: (tbp[0], tbp[1][0], tbp[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if the results are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'Bear doll', 352329.38),\n",
       " (8, 'LEGO Star Wars', 205839.83),\n",
       " (12, 'LEGO Hero Factory', 257001.33000000002),\n",
       " (16, 'LEGO Classic', 362672.58999999997),\n",
       " (24, 'LEGO Pirates', 263908.14999999997),\n",
       " (28, 'Far Cry 4 Limited Edition for Xbox One', 409954.8599999999),\n",
       " (32, 'Intel Core i7 3770K', 181640.36999999997),\n",
       " (36, 'GAM X360 Hitman Absolution X360', 81603.95),\n",
       " (40, 'Might and Magic: Clash Of Heroes PC', 156079.9),\n",
       " (44, 'SAMSUNG LED TV 39F5500, Full HD, USB', 750864.47)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalsByProdNames.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save them as `products_sold.report` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByProdNames.saveAsTextFile('products_sold.report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating by key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last task, use `aggregateByKey` to find average, minimum and maximum price of products bought by each customer (you can use `transByCust` RDD for this). (Hint: your \"zero value\" will need to contain 4 elements: count, sum, minimum and maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, (4124.725, 416.72, 9463.01)),\n",
       " (56, (5053.349411764706, 102.47, 9826.83)),\n",
       " (8, (3860.381, 58.62, 8616.57)),\n",
       " (84, (5891.179999999999, 1312.06, 9874.56)),\n",
       " (40, (5221.209, 1944.72, 9307.77)),\n",
       " (80, (4542.088571428571, 1167.38, 8460.09)),\n",
       " (52, (6483.113333333334, 2786.88, 9995.81)),\n",
       " (4, (3800.122727272727, 568.64, 9325.95)),\n",
       " (100, (5010.055, 1257.63, 9210.55)),\n",
       " (12, (5074.478571428571, 140.46, 9341.65))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transFunc(counters, t):\n",
    "    p = t.price\n",
    "    return [counters[0]+1, min(counters[1], p), max(counters[2], p), counters[3] + p]\n",
    "\n",
    "def mergeFunc(cntr1, cntr2):\n",
    "    return [cntr1[0] + cntr2[0], min(cntr1[1], cntr2[1]), max(cntr1[2], cntr2[2]), cntr1[3] + cntr2[3]]\n",
    "\n",
    "avgMinMaxPerCust = transByCust.aggregateByKey([0, 9999999999999, 0.0, 0.0], transFunc, mergeFunc).\\\n",
    "    mapValues(lambda m: (m[3]/m[0], m[1], m[2]))\n",
    "avgMinMaxPerCust.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
