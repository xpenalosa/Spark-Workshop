{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark GraphX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn about GraphX, Spark's library for handling graphs. You will first use the basic functions on the simple graph modeling the Simpson family. Then you will use some graph algorithms on a larger graph loaded from files.\n",
    "\n",
    "Let's start by importing the necessary classes. Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.graphx._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simpsons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will build the following graph representing a part of the Simpson family:\n",
    "![graph](graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertices are marked with yellow circles and have IDs associated with them. Let's create this graph using this class for representing vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Person(name:String, age:Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `vertices` RDD by parallelizing an array of tuples, each containing the vertex ID (as a Long) and the matching Person object (use the figure as reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val vertices = sc.parallelize(Array((1L, Person(\"Homer\", 39)),\n",
    "    (2L, Person(\"Marge\", 39)), (3L, Person(\"Bart\", 12)),\n",
    "    (4L, Person(\"Milhouse\", 12))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create an `edges` RDD containing `Edge` (which is a Spark GraphX class) elements. Each `Edge` object should be constructed by providing source vertex ID, destination vertex ID and the associated object (a String containing the relation name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val edges = sc.parallelize(Array(Edge(4L, 3L, \"friend\"),\n",
    "    Edge(3L, 1L, \"father\"), Edge(3L, 2L, \"mother\"),\n",
    "    Edge(1L, 2L, \"marriedTo\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use Spark's `Graph` class to construct a graph from those two RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val graph = Graph(vertices, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use graph's `vertices` and `edges` methods to find out how many vertices and edges the graph has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "println(graph.vertices.count())\n",
    "println(graph.edges.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping vertices and edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change String relation descriptions with these objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Relationship(relation:String)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mapEdges` to create a new graph which has `Relationship` objects attached to its edges instead of Strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val newgraph = graph.mapEdges((partId, iter) => iter.map(edge => Relationship(edge.attr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the edges from the new graph (`collect`) to check if everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(Edge(4,3,Relationship(friend)), Edge(3,1,Relationship(father)), Edge(3,2,Relationship(mother)), Edge(1,2,Relationship(marriedTo)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newgraph.edges.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the following class to extend the information about graph's vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class PersonExt(name:String, age:Int, children:Int=0, friends:Int=0, married:Boolean=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new graph by mapping `Person` objects to `PersonExt` objects. Transfer the `name` and `age` fields and leave the rest at defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val newGraphExt = newgraph.mapVertices((vid, person) => PersonExt(person.name, person.age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `aggregateMessages` method to produce new vertices with additional properties in `PersonExt` objects (number of children, number of friends and the married flag). Here is `aggregateMessages` method to refresh your memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```def aggregateMessages[A: ClassTag](\n",
    "        sendMsg: EdgeContext[VD, ED, A] => Unit,\n",
    "        mergeMsg: (A, A) => A,\n",
    "        tripletFields: TripletFields = TripletFields.All)\n",
    "    : VertexRDD[A]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to provide `sendMsg` and `mergeMsg` functions. Model the `EdgeContext` to handle messages (and resulting vertex objects) of tuples each containing number of children, number of friends and the married flag (Int, Int, Boolean). This corresponds to the type `A` in the above definition. You should be able to provide `VD` and `ED` types. \n",
    "`sendMsg` function needs to check incoming context's attribute relation and depending on the type of relation call `sendToSrc` and/or `sendToDst` with the appropriate values.\n",
    "`mergeMsg` function just needs to sum up all the incoming messages for a single vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val aggVertices = newGraphExt.aggregateMessages(\n",
    "    (ctx:EdgeContext[PersonExt, Relationship, Tuple3[Int, Int, Boolean]]) => {\n",
    "        if(ctx.attr.relation == \"marriedTo\")\n",
    "            { ctx.sendToSrc((0, 0, true)); ctx.sendToDst((0, 0, true)); }\n",
    "        else if(ctx.attr.relation == \"mother\" || ctx.attr.relation == \"father\")\n",
    "            { ctx.sendToDst((1, 0, false)); }\n",
    "        else if(ctx.attr.relation == \"friend\")\n",
    "            { ctx.sendToDst((0, 1, false)); ctx.sendToSrc((0, 1, false)); }\n",
    "    },\n",
    "    (msg1:Tuple3[Int, Int, Boolean], msg2:Tuple3[Int, Int, Boolean]) => (msg1._1+msg2._1, msg1._2+msg2._2, msg1._3 || msg2._3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the resulting vertices to check if you have the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,(0,1,false))\n",
      "(1,(1,0,true))\n",
      "(2,(1,0,true))\n",
      "(3,(0,1,false))\n"
     ]
    }
   ],
   "source": [
    "aggVertices.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join this new `VertexRDD` containing calculated values with the graph it was created from using `outerJoinVertices`, shown here as a reminder:\n",
    "\n",
    "```def outerJoinVertices[U:ClassTag, VD2:ClassTag](other: RDD[(VertexId, U)])\n",
    "    (mapFunc: (VertexId, VD, Option[U]) => VD2) : Graph[VD2, ED]```\n",
    "\n",
    "The resulting graph should have `PersonExt` objects attached to its vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val graphAggr = newGraphExt.outerJoinVertices(aggVertices)(\n",
    "    (vid, origPerson, optMsg) => { \n",
    "        optMsg match {\n",
    "            case Some(msg) => PersonExt(origPerson.name, origPerson.age, msg._1, msg._2, msg._3)\n",
    "            case _ => origPerson\n",
    "    }}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the resulting vertices to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,PersonExt(Milhouse,12,0,1,false))\n",
      "(1,PersonExt(Homer,39,1,0,true))\n",
      "(2,PersonExt(Marge,39,1,0,true))\n",
      "(3,PersonExt(Bart,12,0,1,false))\n"
     ]
    }
   ],
   "source": [
    "graphAggr.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will use the “Human Wayfinding in Information Networks” dataset from Stanford University, which is a game that challenges a user to connect two Wikipedia articles with as few links as possible. Two files are important: `articles.tsv` and `links.tsv` (\"tsv\" stands for \"tab-separated values\"). `articles.tsv` contains just a list of all unique article names and `links.tsv` contains a two-by-two list of tab-separated names of articles that are linked.\n",
    "\n",
    "Use the following snippet to load articles, remove empty lines and comments, and assign a unique ID to each article (change the path to where the `first-edition` GitHub repository is cloned if necessary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val articles = sc.textFile(\"../first-edition/ch09/articles.tsv\").\n",
    "    filter(line => line.trim() != \"\" && !line.startsWith(\"#\")).\n",
    "    zipWithIndex().cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the links with this similar snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val links = sc.textFile(\"../first-edition/ch09/links.tsv\").\n",
    "    filter(line => line.trim() != \"\" && !line.startsWith(\"#\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now an excercise in basic RDD operations. Parse each link line to obtain tuples of article names and then join that RDD with `articles` two times to replace article names with their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val linkIndexes = links.map(x => {\n",
    "        val spl = x.split(\"\\t\");\n",
    "        (spl(0), spl(1)) \n",
    "}).join(articles).map(x => x._2).\n",
    "join(articles).map(x => x._2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the resulting RDD, containing source and destination article IDs, to construct a `Graph` using its `fromEdgeTuples` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val wikigraph = Graph.fromEdgeTuples(linkIndexes, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ShortestPaths` object to find the shortest path between two articles called \"14th_century\" and \"Rainbow\". \n",
    "\n",
    "First use the `articles` RDD to find IDs of those articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14th_century,10)\n",
      "(Rainbow,3425)\n"
     ]
    }
   ],
   "source": [
    "articles.filter(x => x._1 == \"Rainbow\" || x._1 == \"14th_century\").\n",
    "    collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the shortest paths algorithm using one of those article IDs as a starting point (first import `ShortestPaths` from `org.apache.spark.graphx.lib`). Search the results to find the value corresponding to the second article. You might need to consult the [documentation](https://spark.apache.org/docs/2.2.0/api/scala/index.html#org.apache.spark.graphx.lib.ShortestPaths$).\n",
    "\n",
    "What is the shortest path between those two articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3425,Map(10 -> 2))\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.graphx.lib._\n",
    "val shortest = ShortestPaths.run(wikigraph, Seq(10))\n",
    "shortest.vertices.filter(x => x._1 == 3425).collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the [Page rank algorithm](https://spark.apache.org/docs/2.0.0/api/scala/index.html#org.apache.spark.graphx.GraphOps@pageRank) on the graph with tolerance of `0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ranked = wikigraph.pageRank(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top five ranked pages by querying the vertices RDD of the resulting graph. (You will have to implement a custom Scala `Ordering`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ordering = new Ordering[Tuple2[VertexId,Double]] {\n",
    "    def compare(x:Tuple2[VertexId, Double], y:Tuple2[VertexId, Double]):Int =\n",
    "    x._2.compareTo(y._2) }\n",
    "val top10 = ranked.vertices.top(10)(ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join these results with the articles RDD to find the matching article names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4297,(43.79545390514789,United_States))\n",
      "(1568,(29.5193874977993,France))\n",
      "(1433,(29.090727549623136,Europe))\n",
      "(4293,(28.602299291981907,United_Kingdom))\n",
      "(1389,(22.334694754966193,English_language))\n",
      "(1694,(22.14622664140612,Germany))\n",
      "(4542,(21.690337661883135,World_War_II))\n",
      "(1385,(20.480194747598016,England))\n",
      "(2417,(20.226473566280973,Latin))\n",
      "(2098,(18.55611493055244,India))\n"
     ]
    }
   ],
   "source": [
    "sc.parallelize(top10).join(articles.map(_.swap)).collect.\n",
    "sortWith((x, y) => x._2._1 > y._2._1).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding connected components of a graph means finding subgraphs in which every vertex can be reached from every other vertex by following the edges in the subgraph. A graph is *connected* if it contains only one connected component and all of its vertices can be reached from every other vertex. \n",
    "\n",
    "Find connected components in the Wikispeedia graph by calling its `connectedComponents` method and save the result in the variable `wikiCC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val wikiCC = wikigraph.connectedComponents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Property objects of the `wikiCC` graph’s vertices contain the lowest vertex ID of the connected component to which they belong. To find the connected components, find distinct values of vertices in the `wikiCC` graph and join them with `articles` RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,(0,%C3%81ed%C3%A1n_mac_Gabr%C3%A1in))\n",
      "(1210,(1210,Directdebit))\n"
     ]
    }
   ],
   "source": [
    "wikiCC.vertices.map(x => (x._2, x._2)).\n",
    "    distinct().join(articles.map(_.swap)).collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many vertices are there in each connected component (count vertices by the attached property objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,4589)\n",
      "(1210,3)\n"
     ]
    }
   ],
   "source": [
    "wikiCC.vertices.map(x => (x._2, x._2)).countByKey().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strongly connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strongly connected components (SCCs) are subgraphs where all vertices are connected to every other vertex in the subgraph (not necessarily directly). All vertices in an SCC need to be reachable from each other (following the direction of the edges).\n",
    "\n",
    "Find strongly connected components of the Wikispeedia graph by calling the `stronglyConnectedComponents` method and specifying 100 as the maximum number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val wikiSCC = wikigraph.stronglyConnectedComponents(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of strongly connected components as you did for connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiSCC.vertices.map(x => x._2).distinct.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the strongly connected components with the largest number of vertices (sort them by the number of vertices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,4051)\n",
      "(2488,6)\n",
      "(1831,3)\n",
      "(892,2)\n",
      "(1950,2)\n",
      "(4224,2)\n",
      "(1111,2)\n",
      "(2474,2)\n",
      "(477,2)\n",
      "(557,2)\n",
      "(2160,2)\n",
      "(1834,2)\n",
      "(2251,2)\n",
      "(1513,2)\n",
      "(2142,2)\n",
      "(1986,2)\n",
      "(195,2)\n",
      "(1976,2)\n",
      "(2321,2)\n"
     ]
    }
   ],
   "source": [
    "wikiSCC.vertices.map(x => (x._2, x._1)).countByKey().\n",
    "filter(_._2 > 1).toList.sortWith((x, y) => x._2 > y._2).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the names of those articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2488,(2488,List_of_African_countries))\n",
      "(2496,(2488,List_of_Oceanian_countries))\n",
      "(2493,(2488,List_of_European_countries))\n",
      "(2498,(2488,List_of_South_American_countries))\n",
      "(2490,(2488,List_of_Asian_countries))\n",
      "(2495,(2488,List_of_North_American_countries))\n"
     ]
    }
   ],
   "source": [
    "wikiSCC.vertices.filter(x => x._2 == 2488).\n",
    "    join(articles.map(x => (x._2, x._1))).collect.foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
